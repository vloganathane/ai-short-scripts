#!/usr/bin/env python3
"""
AI-Powered Public Intelligence Agent - Modular CLI tool for gathering and summarizing public information
Enhanced Contact Information Extraction

Enhanced Contact Information Extraction
Multi-Source Contact Data: Each plugin now extracts relevant contact information:

LinkedIn: Professional emails, locations
Twitter: Bio locations, contact preferences
GitHub: Public emails, geographic locations
Company Directory: Full contact details (email, phone, address)
Web Scraper: Automatic email/phone extraction from web pages
Rich Company Profiles: Company research now includes:

ðŸ“§ Business email addresses
ðŸ“± Direct phone numbers
ðŸ“ Office locations
ðŸ¢ Physical addresses
ðŸ”— LinkedIn profiles
ðŸ” Smart Contact Detection
Regex Pattern Matching: The web scraper automatically detects:

Email addresses using comprehensive patterns
Phone numbers in various formats (+1-555-1234, (555) 123-4567, etc.)
AI Summary Enhancement: The summarizer now:

Extracts and consolidates contact information
Presents it in organized format across all output types
Removes duplicates and validates data
ðŸ“Š Enhanced Output Formats
Text Format: Clean contact summary with emojis

ðŸ“ž CONTACT INFO:
ðŸ“§ Emails: john.doe@company.com, j.doe@gmail.com
ðŸ“± Phones: +1-555-0101, +1-555-0102
JSON Format: Structured contact data

{
  "contact_info": {
    "emails": ["john@company.com"],
    "phones": ["+1-555-0101"]
  }
}
Markdown Format: Professional contact sections

## ðŸ“ž Contact Information
**Emails**: john@company.com
**Phones**: +1-555-0101
ðŸŽ¯ Real-World Usage Examples
# Get full contact details for company employees
python leads.py "employees from TechCorp Inc" --json

# Extract contact info from company website
python leads.py "https://company.com/contact" --markdown

# Research person with contact information
python leads.py "Tell me about John Doe" --json

ðŸš€ Production Integration Points
The enhanced contact extraction is ready for integration with:

Hunter.io: Email finder API
Clearbit: Contact enrichment
ZoomInfo: Business contact database
Apollo.io: B2B contact discovery
Pipl: People search engine

"""

import argparse, json, re, os, sys, urllib.request, urllib.parse
from typing import Dict, Any, List
from abc import ABC, abstractmethod

# Plugin Interface
class DataSource(ABC):
    @abstractmethod
    def fetch_data(self, name: str) -> str:
        pass

# Sample Data Source Plugins
class LinkedInPlugin(DataSource):
    def fetch_data(self, name: str) -> str:
        # Mock enriched LinkedIn data with contact info
        return f"LinkedIn: {name} - Senior Developer at Tech Corp, 5+ years experience. Location: San Francisco, CA. Email: {name.lower().replace(' ', '.')}@techcorp.com"

class TwitterPlugin(DataSource):
    def fetch_data(self, name: str) -> str:
        return f"Twitter: {name} - Tech influencer, 10K followers. Bio location: SF Bay Area. Contact: DM open for collaborations."

class GitHubPlugin(DataSource):
    def fetch_data(self, name: str) -> str:
        return f"GitHub: {name} - 50+ repos, Python/JS expert. Location: California, USA. Public email: {name.lower().replace(' ', '')}@gmail.com"

class CompanyPlugin(DataSource):
    def fetch_data(self, company: str) -> str:
        # Mock enriched company employee data with contact details
        mock_employees = [
            {
                "name": "John Smith", "title": "CEO", 
                "email": f"j.smith@{company.lower().replace(' ', '')}.com",
                "phone": "+1-555-0101", "location": "New York, NY",
                "address": "123 Business Ave, NYC 10001",
                "linkedin": f"linkedin.com/in/john-smith-{company.lower()}"
            },
            {
                "name": "Sarah Johnson", "title": "CTO",
                "email": f"sarah.j@{company.lower().replace(' ', '')}.com", 
                "phone": "+1-555-0102", "location": "San Francisco, CA",
                "address": "456 Tech St, SF 94105",
                "linkedin": f"linkedin.com/in/sarah-johnson-{company.lower()}"
            },
            {
                "name": "Mike Chen", "title": "VP Engineering",
                "email": f"m.chen@{company.lower().replace(' ', '')}.com",
                "phone": "+1-555-0103", "location": "Austin, TX", 
                "address": "789 Innovation Dr, Austin 78701",
                "linkedin": f"linkedin.com/in/mike-chen-{company.lower()}"
            }
        ]
        
        result = f"Company: {company} - Employee Directory\n" + "="*50 + "\n"
        for emp in mock_employees:
            result += f"ðŸ‘¤ {emp['name']} - {emp['title']}\n"
            result += f"   ðŸ“§ {emp['email']}\n"
            result += f"   ðŸ“± {emp['phone']}\n" 
            result += f"   ðŸ“ {emp['location']}\n"
            result += f"   ðŸ¢ {emp['address']}\n"
            result += f"   ðŸ”— {emp['linkedin']}\n\n"
        return result

class WebScraperPlugin(DataSource):
    def fetch_data(self, url: str) -> str:
        """Fetch content from URL and extract contact information"""
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=10) as response:
                content = response.read().decode('utf-8')
                
                # Extract contact information using regex
                emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', content)
                phones = re.findall(r'(?:\+1[-.\s]?)?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}', content)
                
                # Simple text extraction
                text = re.sub(r'<[^>]+>', ' ', content)
                text = ' '.join(text.split())
                text_preview = text[:800] + "..." if len(text) > 800 else text
                
                # Format results with contact info
                result = f"Web Content from {url}:\n{text_preview}\n\n"
                if emails:
                    result += f"ðŸ“§ Found emails: {', '.join(set(emails[:5]))}\n"
                if phones:
                    result += f"ðŸ“± Found phones: {', '.join(set(phones[:3]))}\n"
                
                return result
        except Exception as e:
            return f"Error fetching URL {url}: {str(e)}"

# AI Summarizer Interface
class AISummarizer(ABC):
    @abstractmethod
    def summarize(self, data: str, format_type: str = "text") -> str:
        pass

class MockAISummarizer(AISummarizer):
    def summarize(self, data: str, format_type: str = "text") -> str:
        # Extract contact information from data for summary
        emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', data)
        phones = re.findall(r'(?:\+1[-.\s]?)?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}', data)
        
        summary = "Professional Intelligence Summary: Comprehensive profile with contact details extracted from multiple sources."
        
        contact_info = {}
        if emails:
            contact_info["emails"] = list(set(emails))
        if phones:
            contact_info["phones"] = list(set(phones))
            
        if format_type == "json":
            return json.dumps({
                "summary": summary, 
                "contact_info": contact_info,
                "confidence": 0.8, 
                "sources": ["linkedin", "twitter", "github", "web", "company"]
            }, indent=2)
        elif format_type == "markdown":
            md = f"# Intelligence Summary\n\n{summary}\n\n"
            if contact_info:
                md += "## ðŸ“ž Contact Information\n"
                if "emails" in contact_info:
                    md += f"**Emails**: {', '.join(contact_info['emails'])}\n\n"
                if "phones" in contact_info:
                    md += f"**Phones**: {', '.join(contact_info['phones'])}\n\n"
            md += "## Data Sources\n- LinkedIn\n- Twitter\n- GitHub\n- Web Scraping\n- Company Directory"
            return md
        
        # Text format
        result = summary
        if contact_info:
            result += f"\n\nðŸ“ž CONTACT INFO:"
            if "emails" in contact_info:
                result += f"\nðŸ“§ Emails: {', '.join(contact_info['emails'])}"
            if "phones" in contact_info:
                result += f"\nðŸ“± Phones: {', '.join(contact_info['phones'])}"
        return result

# Multi-Command Parser (MCP)
class MCPParser:
    def __init__(self):
        self.sources_map = {
            "linkedin": LinkedInPlugin(),
            "twitter": TwitterPlugin(), 
            "github": GitHubPlugin(),
            "web": WebScraperPlugin(),
            "company": CompanyPlugin()
        }
    
    def _is_url(self, text: str) -> bool:
        """Check if text is a valid URL"""
        url_pattern = re.compile(r'https?://[^\s]+')
        return bool(url_pattern.search(text))
    
    def _extract_urls(self, command: str) -> List[str]:
        """Extract URLs from command"""
        url_pattern = re.compile(r'https?://[^\s]+')
        return url_pattern.findall(command)
    
    def _extract_company(self, command: str) -> str:
        """Extract company name from command"""
        # Look for company indicators
        company_patterns = [
            r'(?:company|business|firm|corp|corporation|inc|ltd)\s+([A-Z][a-zA-Z\s&]+?)(?:\s|$)',
            r'(?:from|at|of)\s+([A-Z][a-zA-Z\s&]+?)(?:\s+(?:company|corp|inc|ltd|employees|staff|team))',
            r'employees?\s+(?:from|at|of)\s+([A-Z][a-zA-Z\s&]+?)(?:\s|$)',
            r'leads?\s+(?:from|at|of)\s+([A-Z][a-zA-Z\s&]+?)(?:\s|$)'
        ]
        
        for pattern in company_patterns:
            match = re.search(pattern, command, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        return None
    
    def parse_command(self, command: str) -> Dict[str, Any]:
        # Check if command contains URLs
        urls = self._extract_urls(command)
        if urls:
            return {"type": "url", "urls": urls, "sources": ["web"]}
        
        # Check if command is about company research
        company_keywords = ["employees", "staff", "team", "leads", "people from", "workers at"]
        if any(keyword in command.lower() for keyword in company_keywords):
            company = self._extract_company(command)
            if company:
                return {"type": "company", "company": company, "sources": ["company"]}
        
        # Extract person name (simple regex - can be enhanced)
        name_match = re.search(r'about\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', command)
        name = name_match.group(1) if name_match else "Unknown Person"
        
        # Extract sources mentioned (exclude web/company for person searches)
        sources = [s for s in ["linkedin", "twitter", "github"] if s.lower() in command.lower()]
        sources = sources or ["linkedin", "twitter", "github"]  # Default to person sources
        
        return {"type": "person", "name": name, "sources": sources}

# Main Agent Class
class IntelligenceAgent:
    def __init__(self, config_file: str = "agent_config.json"):
        self.parser = MCPParser()
        self.ai = MockAISummarizer()  # Replace with actual AI provider
        self.config = self._load_config(config_file)
    
    def _load_config(self, config_file: str) -> Dict:
        """Load configuration from file or return defaults"""
        default_config = {"ai_provider": "mock", "api_keys": {}}
        try:
            with open(config_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return default_config
    
    def gather_intelligence(self, command: str, output_format: str = "text") -> str:
        """Main intelligence gathering function"""
        try:
            # Parse command using MCP
            parsed = self.parser.parse_command(command)
            
            if parsed["type"] == "url":
                # Handle URL analysis
                gathered_data = []
                for url in parsed["urls"]:
                    plugin = self.parser.sources_map["web"]
                    data = plugin.fetch_data(url)
                    gathered_data.append(f"URL {url}:\n{data}")
                target = "URLs: " + ", ".join(parsed["urls"])
            
            elif parsed["type"] == "company":
                # Handle company research
                company = parsed["company"]
                plugin = self.parser.sources_map["company"]
                data = plugin.fetch_data(company)
                gathered_data = [f"COMPANY RESEARCH:\n{data}"]
                target = f"Company: {company}"
            
            else:
                # Handle person research
                name, sources = parsed["name"], parsed["sources"]
                gathered_data = []
                for source_name in sources:
                    if source_name in self.parser.sources_map:
                        plugin = self.parser.sources_map[source_name]
                        data = plugin.fetch_data(name)
                        gathered_data.append(f"{source_name.upper()}: {data}")
                target = f"Person: {name}"
            
            # Combine and summarize data
            combined_data = "\n".join(gathered_data)
            summary = self.ai.summarize(f"{target}\n\n{combined_data}", output_format)
            
            return summary
            
        except Exception as e:
            return f"Error gathering intelligence: {str(e)}"

# CLI Interface
def main():
    parser = argparse.ArgumentParser(description="AI-Powered Public Intelligence Agent")
    parser.add_argument("command", help="Command: person research, URL analysis, or company leads (e.g., 'employees from TechCorp Inc')")
    parser.add_argument("--json", action="store_true", help="Output in JSON format")
    parser.add_argument("--markdown", action="store_true", help="Output in Markdown format")
    parser.add_argument("--config", default="agent_config.json", help="Configuration file path")
    
    args = parser.parse_args()
    
    # Determine output format
    output_format = "json" if args.json else "markdown" if args.markdown else "text"
    
    # Initialize and run agent
    agent = IntelligenceAgent(args.config)
    result = agent.gather_intelligence(args.command, output_format)
    
    print(result)

# Extension Examples (commented for space)
"""
# To add new data source:
class CustomPlugin(DataSource):
    def fetch_data(self, name: str) -> str:
        return f"Custom data for {name}"

# To add new AI provider:
class OpenAIProvider(AISummarizer):
    def summarize(self, data: str, format_type: str = "text") -> str:
        # OpenAI API call here
        pass

# Usage Examples:
# python leads.py "Tell me about John Doe from LinkedIn and Twitter"
# python leads.py "Research Jane Smith on GitHub" --json
# python leads.py "Find info on Bob Johnson" --markdown
# python leads.py "https://example.com/contact" --json
# python leads.py "Analyze https://company.com/about-us"
# python leads.py "employees from TechCorp Inc" --json
# python leads.py "leads from Acme Corporation" --markdown
# python leads.py "staff at Microsoft Corp"
"""

if __name__ == "__main__":
    main()